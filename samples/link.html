<html>
  <head><title>links</title></head>
  <body>
    <h1>Link(s)</h1>
    <ul>
      <li><a href="https://hackernoon.com/designing-api-contracts-for-legacy-system-modernization">designing api contracts for legacy system modernization</a></li>
      <li><a href="https://www.databricks.com/feed">databricks feed</a></li>
      <li><a href="https://roundup.getdbt.com/feed">getdbt.com feed</a></li>
    </ul>

    <h1>articles</h1>
    <a href="https://gradientflow.substack.com/p/data-engineering-for-machine-users">Data Engineering in 2026: What Changes?</a>
    <p>In the 2026 agent-native era, data engineering focuses on AI agents as the primary "machine users," prioritizing automation, reliability, and safety amid agents driving over 80% of new database creations and surging prompt volumes. Key shifts include modular PARK (PyTorch, AI Models, Ray, and Kubernetes) stacks, multimodal lakehouses, context stores for business logic, confidence-gated execution for safety, and ephemeral databases.</p>

    <a href="https://blog.gopenai.com/from-local-to-global-a-deep-dive-into-graphrag-1c50e2fc9e65">From Local to Global: A Deep Dive into GraphRAG</a>
    <p>GraphRAG enhances conventional RAG by building a hierarchical knowledge graph from raw documents, enabling both granular local retrieval and global corpus-level reasoning for LLMs. GraphRAG synthesizes high-level insights and reduces hallucinations by using token-overlapping chunking, entity resolution, weighted relationships, and recursive community detection. The dual Local/Global retrieval modes resolve prior trade-offs between precision and corpus-wide understanding at the cost of pre-computation.</p>

    <a href="https://ragaboutit.com/the-adaptive-retrieval-advantage-why-query-aware-rag-is-replacing-one-size-fits-all-retrieval/">The Adaptive Retrieval Advantage: Why Query-Aware RAG Is Replacing One-Size-Fits-All Retrieval</a>
    <p>Lightweight query classification slashes RAG costs and latency while boosting precision for complex enterprise queries.</p>

    <a href="https://www.philschmid.de/mcp-cli">Introducing MCP CLI: A way to call MCP Servers Efficiently</a>
    <p>2026-01-09</p>
    <p>MCP-CLI is a lightweight, open-source command-line tool that enables efficient, dynamic interaction with Model Context Protocol (MCP) servers. By supporting just-in-time tool discovery and execution instead of statically loading all tool definitions, it drastically reduces token consumption (up to 99% savings), making it ideal for AI coding agents like Gemini CLI or Claude Code.</p>

    <a href="https://www.pinecone.io/learn/rag-access-control/">RAG with Access Control</a>
    <p>2026-01-08</p>
    <p>Relationship-Based Access Control (ReBAC) models data access as a graph of relationships between users and resources, providing flexibility for dynamic and context-rich applications. SpiceDB, an open-source Zanzibar-based ReBAC implementation, can be integrated with vector databases like Pinecone to secure RAG pipelines with fine-grained policies. OpenAI uses SpiceDB to enforce access policies over 37 billion documents across 5 million ChatGPT Connector users, effectively preventing information leakage when serving domain-specific knowledge.</p>

    <a href="https://www.dataengineeringweekly.com/p/a-critique-of-iceberg-rest-catalog">A Critique of Iceberg REST Catalog: A Classic Case of Why Semantic Spec Fails</a>
    <p>2026-01-09</p>
    <p>Apache Iceberg's REST Catalog specification ensures semantic interoperability, enabling diverse engines such as Trino, Spark, and Flink to interact seamlessly via a universal API. However, the standard omits operational guarantees (no defined latency, throughput, or synchronization SLAs), leading to unpredictable performance, high retry amplification, and systemic instability as table and catalog counts scale. This lack of operational constraints shifts the burden to clients and operators, making systems fragile and hard to maintain, highlighting the need for explicit behavioral contracts and conformance testing to ensure reliability at enterprise scale.</p>

    <a href="https://thenewstack.io/openeverest-a-tool-to-manage-multiple-databases-on-kubernetes/">OpenEverest, a Tool To Manage Multiple Databases on Kubernetes</a>
    <p>2026-01-09</p>
    <p>Percona has donated OpenEverest, a unified Kubernetes-native database management tool that supports PostgreSQL, MySQL, and MongoDB, to the CNCF under Apache 2.0 open source licensing. OpenEverest enables vendor-agnostic provisioning, high availability, disaster recovery, and autoscaling through standardized CRDs and RESTful APIs, simplifying database ops without requiring database-specific expertise.</p>

    <a href="https://ai.gopubby.com/autorag-the-end-of-guesswork-in-retrieval-augmented-generation-cc9ac0ad578c"> AutoRAG: The End of Guesswork in Retrieval-Augmented Generation</a>
    <p>2026-01-12</p>
    <p>AutoRAG is a system that automatically tests and tunes different RAG pipeline setups to find what works best for each task. Instead of hand-tuning chunking, retrieval, reranking, and prompts, you define the evaluation metric and let it optimize the pipeline end-to-end. </p>

    <a href="https://www.ssp.sh/blog/diary-of-a-data-engineer/"> A Diary of a Data Engineer</a>
    <p>2026-01-13</p>
    <p> The core essence and challenges of data engineering remain unchanged despite decades of tool evolution from early ETL/SSIS in the 2000s, through Hadoop/big data hype, to modern stacks like dbt, Iceberg, and AI agents in 2026. Key insights include the eternal loop ("The tools change. The loop doesn't."), the lost art of proper data modeling, treating schema issues as people problems, and focusing on fundamentals over trends.</p>

    <a href="https://medium.com/@zeta-decoded/zetas-lakehouse-journey-a-composable-scalable-and-federated-architecture-df0ab5f19c3a">Zeta’s Lakehouse Journey: A Composable, Scalable, and Federated Architecture </a>
    <p>2026-01-13</p>
    <p>Zeta built a composable, scalable, and federated Lakehouse architecture with Apache Iceberg on S3Table/AWS Glue Catalog and a multi-account federated setup to unify heterogeneous data from acquisitions, enable secure cross-team access without duplication, support diverse compute engines (Spark, Snowflake, ClickHouse, and Trino) for AI/marketing workloads, and ensure governance, schema evolution, and vendor independence. </p>

    <a href="https://github.com/matsonj/mviz">mviz (GitHub Repo)</a>
    <p> </p>
    <p>mviz is a lightweight tool that lets you turn small JSON specs into polished HTML or PDF reports through Claude, so you can explore data, iterate quickly, and share results without building dashboards or infrastructure. It focuses on fast, AI-native analysis workflows with minimal boilerplate and high-quality static outputs that are easy to export and reuse.</p>

    <a href="https://towardsdatascience.com/you-probably-dont-need-a-vector-database-for-your-rag-yet/">You Probably Don't Need a Vector Database for Your RAG — Yet</a>
    <p>2026-01-20</p>
    <p>For small-to-medium RAG pipelines, NumPy and scikit-learn can deliver millisecond-level in-memory vector search on millions of records, eliminating the overhead and complexity of dedicated vector databases like Pinecone or Weaviate. Using pure matrix multiplication and tree-based search (KD/Ball-Tree), typical workloads up to ~1.5GB of embeddings (e.g., 1M vectors × 384-dim) perform efficiently without network serialization or CRUD demands. Transition to vector databases only when persistence, high-frequency updates, metadata filtering, or RAM limits are required.</p>

    <a href="https://www.astronomer.io/blog/building-data-pipelines-like-assembly-lines/">Building Data Pipelines Like Assembly Lines</a>
    <p>2026-01-19</p>
    <p>A small data engineering team stopped building one-off Airflow pipelines and instead created a declarative factory where every dataset follows the same write, test, and publish pattern. By encoding testing, documentation, dependency management, and safety into reusable components, they can ship new pipelines in hours instead of days and avoid bad data reaching production.</p>

    <a href="https://medium.com/@sanjeebmeister/apache-spark-performance-tuning-on-amazon-emr-a-complete-guide-part2-3a0deda7d0c7">Apache Spark Performance Tuning on Amazon EMR</a>
    <p>2026-01-19</p>
    <p>Optimal Spark performance on EMR demands strategic tuning, rather than additional compute, to prevent wasted costs and degradation from shuffle overhead, GC pressure, and network contention. Key optimizations include executor sizing, memory management, partition and shuffle tuning, caching, column/prune elimination, predicate pushdown, handling small files, and leveraging Z-ordering for “haystack queries”. Benchmarks show a 10x difference in 1TB S3 read times based solely on data organization and configuration.</p>
    
    <a href="https://dropbox.tech/machine-learning/vp-josh-clemm-knowledge-graphs-mcp-and-dspy-dash">Engineering VP Josh Clemm on How We Use Knowledge Graphs, MCP, and DSPy in Dash </a>
    <p>2026-01-28</p>
    <p> By giving Dash access to proprietary work content, it unifies search, Q&A, and agentic tasks across Dropbox files and third-party apps. Dash ingests data via custom connectors, generates multimodal embeddings and knowledge graphs for entity relationships, and uses hybrid retrieval (BM25 + dense vectors) for fast retrieval. It optimizes MCP tool calling and tunes 30+ prompts (including LLM-as-judge) for better relevance, fewer disagreements, and easier model iteration.</p>
    
    <a href="https://loglevelinfo.substack.com/p/how-i-structure-my-data-pipelines-a20">How I Structure My Data Pipelines: The Silver Layer </a>
    <p>2026-01-29</p>
    <p>The Silver layer combines Medallion (Bronze-Silver-Gold) with Kimball dimensional modeling, serving as the core by organizing data into business-domain schemas with facts (granular events) and dimensions (attributes with surrogate keys), using intermediates for reusable transformations, and RLS/CLM access controls. This design ensures predictability, schema evolution, isolation of business logic in Silver, and composability. </p>
    
    <a href="https://netflixtechblog.medium.com/data-bridge-how-netflix-simplifies-data-movement-36d10d91c313"> Data Bridge: How Netflix simplifies data movement</a>
    <p> </p>
    <p>Netflix's Data Bridge unifies and abstracts batch data movement across more than three dozen source-destination pairs, eliminating fragmentation from bespoke tools. As a programmable control plane, it orchestrates ~300,000 jobs per week via a no-code/low-code interface, intent-based API, and YAML configs, centralizing metadata, governance, and job management. The platform's pluggable architecture streamlines connector contributions and enables seamless transitions to new data movement implementations. </p>
    
    <a href="https://openai.com/index/inside-our-in-house-data-agent/">Inside OpenAI's in-house data agent </a>
    <p>2026-01-29</p>
    <p>OpenAI built a bespoke internal AI data agent powered by GPT-5 that lets employees ask natural-language questions and get accurate, contextual data insights end to end, from table discovery to analysis and reporting. It combines code-aware data context, institutional knowledge, memory, and continuous evaluation to deliver fast, reliable analytics at OpenAI's scale. </p>
    <a href="https://fieldnotesondata.substack.com/p/how-not-to-run-an-open-standards">How Not to Run an Open Standards Initiative </a>
    <p> 2026-02-08</p>
    <p>OSI is an open standard for semantic layer interoperability, but in practice, it fails due to vendor capture, weak governance, and a lack of neutral stewardship or migration paths. Open standards succeed through trust, incentives, and institutional design, not by publishing a spec. </p>
    
    <a href="https://blog.pmunhoz.com/dbt/dbt-defer-optimize-cicd-pipelines"> dbt Defer: Speed Up CI/CD Pipelines and Slash Compute Costs by 75%</a>
    <p> 2026-02-05</p>
    <p> Implementing dbt's defer feature in CI pipelines dramatically accelerates builds and reduces cloud compute costs by 60–80%, as it reuses existing production artifacts and rebuilds only modified models instead of the entire dependency chain. By storing and referencing production manifest files, teams can achieve up to a 75% runtime reduction on small projects and cut 20-minute builds to under 5 minutes on enterprise-scale warehouses. Defer supports advanced patterns, including integration with local development and selective full refreshes, while requiring careful manifest and schema management to avoid pitfalls.</p>
    
    <a href="https://www.infoworld.com/article/4127318/the-super-bowl-standard-architecting-distributed-systems-for-massive-concurrency.html">The ‘Super Bowl' standard: Architecting distributed systems for massive concurrency </a>
    <p> 2026-02-05</p>
    <p>Surviving extreme load events like the “Super Bowl standard” requires more than auto-scaling. Critical architectural patterns include aggressive load shedding based on business priority, strict tenancy isolation (bulkheads/circuit breakers), and sophisticated request collapsing to prevent cache stampedes. These strategies, combined with regular “game day” drills that simulate 50%+ above-peak loads, ensure systems fail gracefully, maintaining core functionality under duress. </p>

    <a href="https://engineering.fb.com/2026/02/09/data-center-engineering/building-prometheus-how-backend-aggregation-enables-gigawatt-scale-ai-clusters/"> Building Prometheus: How Backend Aggregation Enables Gigawatt-Scale AI Clusters</a>
    <p> 2026-02-09</p>
    <p> Meta's Prometheus AI cluster will deliver 1 GW of capacity by interconnecting tens of thousands of GPUs across numerous data centers, enabled by the Backend Aggregation (BAG) network. BAG employs modular Jericho3 ASIC-powered chassis, petabit-level inter-BAG bandwidth (up to 48 Pbps per region pair), and advanced Ethernet-based topologies with eBGP routing and MACsec security. Precise oversubscription management and distributed architecture ensure high-performance, resilient networking.</p>
    
    <a href="https://netflixtechblog.medium.com/high-throughput-graph-abstraction-at-netflix-part-i-e88063e6f6d5">High-Throughput Graph Abstraction at Netflix: Part I </a>
    <p> 2026-02-10</p>
    <p> Netflix's Graph Abstraction processes up to 10 million ops/sec across 650TB of graph data, integrating seamlessly with their KV and time-series abstractions for cost-efficient, low-latency (single-digit ms) access and strong eventual consistency. It employs a modular Property Graph model, fine-grained schema management, advanced caching with EVCache, and robust asynchronous operations for scalability and resilience. This architecture enables rapid traversals, fine schema control, and reliable multi-region operation.</p>

    <a href="https://medium.com/pinterest-engineering/drastically-reducing-out-of-memory-errors-in-apache-spark-at-pinterest-c55d7dac2257">Drastically Reducing Out-of-Memory Errors in Apache Spark at Pinterest </a>
    <p> 2026-02-18</p>
    <p> Pinterest developed the Auto Memory Retries feature, which automatically retries OOM-failed tasks first by increasing CPU allocation to reduce contention, then launching bigger executors with 2x/3x/4x resource profiles scaling memory, overhead, and off-heap for Gluten jobs. This resulted in a 96% reduction in OOM failures, compute cost savings, and reduced manual tuning efforts on common culprits like severe data skew or unpredictable per-task memory spikes.</p>

    <a href="https://medium.com/agoda-engineering/how-to-convert-any-api-to-mcp-with-zero-code-and-zero-deployments-using-apiagent-fa494de8eaee">Agoda's API Agent Converts Any API to MCP with Zero Code and Deployments </a>
    <p> 2026-01-27</p>
    <p> Agoda's API Agent enables zero-code, zero-deployment transformation of any internal REST or GraphQL API into an MCP endpoint, streamlining AI-driven queries across heterogeneous systems. With automated schema introspection, in-process DuckDB for context-limited summarization, and robust support for security and observability, teams can rapidly connect and query multiple APIs from a single MCP server by merely updating configurations.</p>

    <a href="https://www.dremio.com/blog/apache-polaris-graduates-to-a-top-level-apache-project/"> Apache Polaris Graduates to a Top-Level Apache Project</a>
    <p> 2026-02-18</p>
    <p>Apache Polaris is now a Top-Level Project at the ASF, marking vendor-neutral governance and strong community backing with 100+ contributors across eight organizations. In 18 months, it delivered six releases, closed 2,800+ pull requests, and standardized the Apache Iceberg REST Catalog across engines like Dremio, Spark, Flink, and Trino. </p>

    
    <a href=""> </a>
    <p> </p>
    <p> </p>
  </body>
</html>
